{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns\n",
        "from scipy.stats import entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# loading both sheets from the excel file\n",
        "fn = \"/content/data.xlsx\"\n",
        "borrowers = pd.read_excel(fn, sheet_name=\"borrowers\", header=[0,1])\n",
        "stress = pd.read_excel(fn, sheet_name=\"stress_test_scenarios\", header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# flattening the multi-index cols\n",
        "borrowers.columns = [f\"{a}_{b}\".strip().replace(\" \", \"_\") for a,b in borrowers.columns]\n",
        "id_col = borrowers.columns[0]\n",
        "\n",
        "# splitting columns into groups (ratings, amounts, LGD, EAD)\n",
        "ratings_cols = [c for c in borrowers.columns if c.startswith(\"Ratings_\")]\n",
        "amount_cols  = [c for c in borrowers.columns if c.startswith(\"Amount_in_Rs_Crore_\")]\n",
        "lgd_cols     = [c for c in borrowers.columns if c.startswith(\"Loss_Given_Default_\")]\n",
        "ead_cols     = [c for c in borrowers.columns if c.startswith(\"Exposure_at_Default\")]\n",
        "\n",
        "year_labels = [f\"Year_{i}\" for i in range(1,11)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# helper fn to clean up each block into one df\n",
        "def fixcols(cols):\n",
        "    out = borrowers[cols].copy()\n",
        "    out.columns = year_labels\n",
        "    out.insert(0, \"Borrower\", borrowers[id_col])\n",
        "    out.set_index(\"Borrower\", inplace=True)\n",
        "    return out\n",
        "\n",
        "ratings_df = fixcols(ratings_cols)\n",
        "amount_df  = fixcols(amount_cols).apply(pd.to_numeric, errors='coerce')\n",
        "lgd_df     = fixcols(lgd_cols).apply(pd.to_numeric, errors='coerce')\n",
        "ead_df     = fixcols(ead_cols).apply(pd.to_numeric, errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# fixing LGD display values\n",
        "if lgd_df.values.max() > 1.5:\n",
        "    lgd_df /= 100.0\n",
        "\n",
        "# computing exposure\n",
        "exposure_df = amount_df * ead_df\n",
        "ratings_df = ratings_df.map(lambda x: str(x).strip().upper() if pd.notna(x) else x)\n",
        "\n",
        "order = ['AAA','AA','A','BBB','BB','B','C','D']\n",
        "all_ratings = sorted({r for r in ratings_df.values.ravel() if pd.notna(r)},\n",
        "                     key=lambda x: order.index(x) if x in order else 99)\n",
        "print(\"Detected ratings:\", all_ratings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transition Matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# making transition matrices (count + prob)\n",
        "def transition(df, y1, y2):\n",
        "    c = pd.crosstab(df[f\"Year_{y1}\"], df[f\"Year_{y2}\"]).reindex(\n",
        "        index=all_ratings, columns=all_ratings, fill_value=0)\n",
        "    p = c.div(c.sum(axis=1).replace(0, np.nan), axis=0).fillna(0)\n",
        "    return c, p\n",
        "\n",
        "counts, probs = {}, {}\n",
        "for t in range(1,10):\n",
        "    counts[t], probs[t] = transition(ratings_df, t, t+1)\n",
        "\n",
        "# exporting transition matrices into excel\n",
        "with pd.ExcelWriter(\"transition_matrices.xlsx\") as writer:\n",
        "    for t in range(1,10):\n",
        "        counts[t].to_excel(writer, sheet_name=f\"Counts_Y{t}_Y{t+1}\")\n",
        "        probs[t].to_excel(writer, sheet_name=f\"Trans_Y{t}_Y{t+1}\")\n",
        "\n",
        "# plotting the heatmaps for transition matrices\n",
        "for t in range(1,10):\n",
        "    plt.figure(figsize=(5,4))\n",
        "    sns.heatmap(probs[t], cmap=\"viridis\", annot=False)\n",
        "    plt.title(f\"Transition Matrix Year {t} → {t+1}\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Probability of Default (PD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# computing PDs (per rating + portfolio weighted PD)\n",
        "pd_ratings = pd.DataFrame(index=all_ratings, columns=[f\"Year_{y}\" for y in range(2,11)])\n",
        "port_pd = pd.Series(index=[f\"Year_{y}\" for y in range(2,11)])\n",
        "\n",
        "for t in range(1,10):\n",
        "    p = probs[t]\n",
        "    pd_ratings[f\"Year_{t+1}\"] = p['D']\n",
        "\n",
        "    exp = exposure_df[f\"Year_{t}\"]\n",
        "    r = ratings_df[f\"Year_{t}\"]\n",
        "    w = exp.groupby(r).sum().reindex(all_ratings).fillna(0)\n",
        "\n",
        "    port_pd[f\"Year_{t+1}\"] = (w / w.sum() * p['D']).sum()\n",
        "\n",
        "print(\"\\nRating-level PDs:\")\n",
        "display(pd_ratings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Expected Loss (EL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# expected loss calculation (rating-wise + portfolio)\n",
        "el_by_rating = pd.DataFrame(index=all_ratings, columns=[f\"Year_{y}\" for y in range(2,11)])\n",
        "port_el = pd.Series(index=[f\"Year_{y}\" for y in range(2,11)])\n",
        "\n",
        "for t in range(1,10):\n",
        "    exp, lgd, r = exposure_df[f\"Year_{t}\"], lgd_df[f\"Year_{t}\"], ratings_df[f\"Year_{t}\"]\n",
        "    df = pd.DataFrame({'E': exp, 'L': lgd, 'R': r})\n",
        "    df['PD'] = df['R'].map(probs[t]['D'])\n",
        "    df['EL'] = df.E * df.L * df.PD\n",
        "\n",
        "    el_by_rating[f\"Year_{t+1}\"] = df.groupby('R').EL.sum().reindex(all_ratings).fillna(0)\n",
        "    port_el[f\"Year_{t+1}\"] = df.EL.sum()\n",
        "\n",
        "print(\"\\nRating-level ELs:\")\n",
        "display(el_by_rating)\n",
        "\n",
        "el_by_rating.to_excel(\"el_by_rating.xlsx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cumulative PD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cumulative PD calculation (5yr and 10yr) using matrix multiplication\n",
        "def make_abs(p):\n",
        "    q = p.copy()\n",
        "    if 'D' in q.index:\n",
        "        q.loc['D'] = 0\n",
        "        q.at['D','D'] = 1\n",
        "    return q.reindex(index=all_ratings, columns=all_ratings, fill_value=0)\n",
        "\n",
        "M5 = np.linalg.multi_dot([make_abs(probs[t]).values for t in range(1,5)])\n",
        "M10 = np.linalg.multi_dot([make_abs(probs[t]).values for t in range(1,10)])\n",
        "\n",
        "M5 = pd.DataFrame(M5, index=all_ratings, columns=all_ratings)\n",
        "M10 = pd.DataFrame(M10, index=all_ratings, columns=all_ratings)\n",
        "\n",
        "cum5, cum10 = M5['D'], M10['D']\n",
        "\n",
        "w = exposure_df['Year_1'].groupby(ratings_df['Year_1']).sum().reindex(all_ratings).fillna(0)\n",
        "p5 = (w/w.sum() * cum5).sum()\n",
        "p10 = (w/w.sum() * cum10).sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Stress Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# stress test I (LGD multipliers)\n",
        "mults = None\n",
        "for _, row in stress.iterrows():\n",
        "    nums = pd.to_numeric(row, errors='coerce').dropna().values\n",
        "    if len(nums) >= 10:\n",
        "        mults = [float(x) for x in nums[:10]]\n",
        "        break\n",
        "\n",
        "if mults is None:\n",
        "    raise ValueError(\"Couldn't find numeric LGD multipliers in stress sheet.\")\n",
        "\n",
        "mult = pd.Series(mults, index=[f\"Year_{i}\" for i in range(1,11)])\n",
        "\n",
        "lgd_s = lgd_df.copy()\n",
        "for y in range(1,11):\n",
        "    lgd_s[f\"Year_{y}\"] = np.minimum(1.0, lgd_df[f\"Year_{y}\"] * mult[f\"Year_{y}\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compute ELs again using stressed LGD\n",
        "el_by_rating_s = pd.DataFrame(index=all_ratings, columns=[f\"Year_{y}\" for y in range(2,11)])\n",
        "port_el_s = pd.Series(index=[f\"Year_{y}\" for y in range(2,11)])\n",
        "\n",
        "for t in range(1,10):\n",
        "    exp, lgd, r = exposure_df[f\"Year_{t}\"], lgd_s[f\"Year_{t}\"], ratings_df[f\"Year_{t}\"]\n",
        "\n",
        "    df = pd.DataFrame({'E': exp, 'L': lgd, 'R': r})\n",
        "    df['PD'] = df['R'].map(probs[t]['D'])\n",
        "    df['EL'] = df.E * df.L * df.PD\n",
        "\n",
        "    el_by_rating_s[f\"Year_{t+1}\"] = df.groupby('R').EL.sum().reindex(all_ratings).fillna(0)\n",
        "    port_el_s[f\"Year_{t+1}\"] = df.EL.sum()\n",
        "\n",
        "print(\"\\nRating-level Stress I ELs:\")\n",
        "display(el_by_rating_s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# stress test II (forced downgrade mapping)\n",
        "mapping_row = None\n",
        "for i, row in stress.iterrows():\n",
        "    vals = [str(x).strip().upper() for x in row if isinstance(x, str)]\n",
        "    if 'AAA' in vals and 'D' in vals:\n",
        "        mapping_row = row\n",
        "        break\n",
        "\n",
        "if mapping_row is not None:\n",
        "    mapping_idx = stress.index.get_loc(i)\n",
        "    mapping_targets = [str(x).strip().upper() for x in stress.iloc[mapping_idx+1] if isinstance(x, str)]\n",
        "    srcs = ['AAA','AA','A','BBB','BB','B','C','D']\n",
        "    downgrade = dict(zip(srcs, mapping_targets[:8]))\n",
        "else:\n",
        "    # fallback to downgrade mapping if nothing found\n",
        "    downgrade = dict(zip(['AAA','AA','A','BBB','BB','B','C','D'],\n",
        "                         ['BBB','A','B','B','C','D','D','D']))\n",
        "\n",
        "r9 = ratings_df['Year_9']\n",
        "r10s = r9.map(lambda x: downgrade.get(x, x))\n",
        "\n",
        "print(\"\\nRating distribution Year 9:\")\n",
        "print(r9.value_counts().reindex(all_ratings).fillna(0))\n",
        "\n",
        "print(\"\\nRating distribution Year 10 AFTER forced downgrade:\")\n",
        "print(r10s.value_counts().reindex(all_ratings).fillna(0))\n",
        "\n",
        "exp9, lgd9 = exposure_df['Year_9'], lgd_df['Year_9']\n",
        "pd10 = probs[9]['D']\n",
        "\n",
        "el10_base = port_el['Year_10']\n",
        "el10_stress = (exp9 * lgd9 * r10s.map(pd10)).sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extras and output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# some extra analytics (stability + KL div)\n",
        "diag = pd.DataFrame({t: np.diag(probs[t]) for t in probs})\n",
        "diag.index = all_ratings\n",
        "stability = diag.std(axis=1)\n",
        "\n",
        "print(\"\\nRating stability (lower = more stable):\")\n",
        "print(stability)\n",
        "\n",
        "print(\"\\nMost stable rating:\", stability.idxmin())\n",
        "\n",
        "dist = pd.DataFrame({\n",
        "    y: exposure_df[y].groupby(ratings_df[y]).sum().reindex(all_ratings).fillna(0)\n",
        "    for y in [f\"Year_{i}\" for i in range(1,11)]\n",
        "})\n",
        "\n",
        "pdist = dist.div(dist.sum())\n",
        "\n",
        "kl = {}\n",
        "years = list(pdist.columns)\n",
        "for i in range(len(years)-1):\n",
        "    kl[f\"{years[i]}→{years[i+1]}\"] = entropy(pdist[years[i]], pdist[years[i+1]])\n",
        "\n",
        "print(\"\\nKL divergence (rating distribution shifts):\")\n",
        "print(pd.Series(kl))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# basic visuals for PD + EL trends + rating mix\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(port_pd.index, port_pd.values)\n",
        "plt.title(\"Portfolio PD Over Time\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(port_el.index, port_el.values, label=\"Baseline EL\")\n",
        "plt.plot(port_el_s.index, port_el_s.values, label=\"Stress I EL\")\n",
        "plt.title(\"Baseline vs Stress EL\")\n",
        "plt.legend()\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "sns.heatmap(pd_ratings.astype(float), cmap=\"magma\")\n",
        "plt.title(\"PD by Rating Over Time\")\n",
        "plt.show()\n",
        "\n",
        "comp = {\n",
        "    f\"Year_{y}\": exposure_df[f'Year_{y}'].groupby(ratings_df[f'Year_{y}']).sum().reindex(all_ratings).fillna(0)\n",
        "    for y in range(1,11)\n",
        "}\n",
        "comp_df = pd.DataFrame(comp).T\n",
        "(comp_df / comp_df.sum(axis=1).values.reshape(-1,1)).plot.area(figsize=(10,4))\n",
        "plt.title(\"Rating Composition by Exposure\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# printing final summary numbers\n",
        "print(\"\\nPortfolio PDs:\\n\", port_pd.round(4))\n",
        "print(\"\\nPortfolio ELs:\\n\", port_el.round(4))\n",
        "print(\"\\nStress I ELs:\\n\", port_el_s.round(4))\n",
        "print(\"\\nΔEL Stress I:\\n\", (port_el_s - port_el).round(4))\n",
        "print(f\"\\nCumulative PD 5y = {p5:.4f}, 10y = {p10:.4f}\")\n",
        "print(f\"\\nStress II Year10 EL baseline = {el10_base:.4f}, stressed = {el10_stress:.4f}, Δ = {(el10_stress - el10_base):.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
